{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade2b6fe-66a0-4eb9-b492-881c3f5dcf1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.11.3 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86bcb6a3-64a0-4041-abf5-72a9113fb744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.cloud import bigquery\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70607f5c-985a-4fe5-8fdb-d0b201af044a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-02-780f38a9daf1\"\n",
    "LOCATION = \"us-central1\"\n",
    "MODEL = \"gemini-2.0-flash-001\"\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "SYSTEM_INSTRUCTION_TEXT = \"\"\"\n",
    "Refer to the data provided to answer questions about this city.\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client = bigquery.Client()\n",
    "\n",
    "def vector_search_bq(search_word):\n",
    "    # Vector Search for Embeddings\n",
    "    QUERY = (\n",
    "        \"\"\"\n",
    "        SELECT query.query, base.question, base.answer\n",
    "        FROM VECTOR_SEARCH(\n",
    "          TABLE `qwiklabs-gcp-02-780f38a9daf1.challenge_2.aurora_bay_faqs_with_embeddings`, 'ml_generate_embedding_result',\n",
    "          (\n",
    "          SELECT text_embedding, content AS query\n",
    "          FROM ML.GENERATE_TEXT_EMBEDDING(\n",
    "          MODEL `challenge_2.embedding_model`,\n",
    "          (SELECT @search_word AS content))\n",
    "          ),\n",
    "          top_k => 5, options => '{\"fraction_lists_to_search\": 0.01}')\n",
    "          \"\"\"\n",
    "        )\n",
    "\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters = [\n",
    "            bigquery.ScalarQueryParameter(\"search_word\", \"STRING\", search_word)\n",
    "        ])\n",
    "    query_job = bigquery_client.query(QUERY, job_config = job_config)\n",
    "    rows = [dict(row) for row in query_job.result()]\n",
    "    if len(rows)==0:\n",
    "        rows = []\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "def start_chat():\n",
    "    # Configure Gemini\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature = 1,\n",
    "        top_p = 0.95,\n",
    "        max_output_tokens = 8192,\n",
    "        response_modalities = [\"TEXT\"],\n",
    "        safety_settings = [types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "          threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "          threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "          threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "          threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "        )],\n",
    "        system_instruction=[types.Part.from_text(text=SYSTEM_INSTRUCTION_TEXT)],\n",
    "      )    \n",
    "    contents = []\n",
    "    # Start chat\n",
    "    print(\"Type 'exit' to stop chatting\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input == \"exit\":\n",
    "            break\n",
    "        \n",
    "        # Query Embeddings from User Input\n",
    "        bigquery_content = vector_search_bq(user_input)\n",
    "        \n",
    "        reference = types.Part.from_function_call(\n",
    "            name=\"reference\",\n",
    "            args={\n",
    "                \"json_data\": json.dumps(bigquery_content)\n",
    "            }\n",
    "        )               \n",
    "        contents.append(\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=user_input),\n",
    "                    reference\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        response = []\n",
    "        print(\"Model: \\n\")\n",
    "        # Model output\n",
    "        for chunk in client.models.generate_content_stream(model = MODEL,contents = contents,config = generate_content_config):\n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\")\n",
    "                response.append(chunk.text)\n",
    "        \n",
    "        contents.append(\n",
    "            types.Content(\n",
    "                role=\"model\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=chunk.text)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a2301-518e-4ed2-bc8c-e65d1f2cdb90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to stop chatting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  tax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "\n",
      "Okay, I'm ready. Please provide the data about the city and ask your questions. I will do my best to answer them using the provided information.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  tell me about rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "\n",
      "Please specify what kind of rate you're interested in. I have information on business tax rates and noise ordinance hours.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  both\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "\n",
      "Here's some information about business tax rates and noise ordinances in Aurora Bay:\n",
      "\n",
      "*   **Business Tax Rates:** Business taxes include a 4% sales tax and a 2% local business tax on net profits, in addition to any applicable state taxes.\n",
      "*   **Noise Ordinances:** Residential noise ordinances go into effect from 10 PM to 6 AM on weekdays and from 11 PM to 7 AM on weekends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0ddb5-3eb9-4524-b69b-3f6d47a1d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
